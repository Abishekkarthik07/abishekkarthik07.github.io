---
layout: single
author_profile: true
title: "Internships"
permalink: /internships/
---

# Internships

My internship journey has been shaped by a consistent effort to understand how artificial intelligence behaves outside controlled experiments. Across different environments, I learned that deploying AI is less about achieving peak benchmark performance and more about building systems that survive ambiguity, evolve with changing inputs, and earn user trust over time. Each role pushed me to think beyond models in isolation and toward AI as part of a larger, living system.

---

## ECSite

At ECSite in San Jose, I worked on automating workflows over unstructured enterprise data, where real-world messiness was the default rather than the exception. Documents varied constantly in layout, terminology, and quality, making rigid automation brittle and unreliable. This environment forced me to rethink how AI pipelines should be designed when assumptions regularly break.

I developed modular, NLP-driven workflows that emphasized adaptability over rigidity, using orchestration tools like n8n and Make.com. Rather than optimizing for a single ideal case, I focused on building pipelines that could detect anomalies, recover gracefully from errors, and remain interpretable to engineers maintaining them. Integrating Python services with MongoDB and SharePoint exposed me to the complexity of legacy enterprise systems and taught me that robustness often comes from thoughtful system design rather than more complex models.

This experience reshaped how I think about intelligence in production systems, where resilience and clarity matter as much as accuracy.

---

## Rencata

At Rencata in Chennai, I worked on developing natural language interfaces for enterprise databases. The goal was to enable users to query complex relational data without requiring technical expertise, which revealed how fragile language-driven systems can be when exposed to real users.

I built a GPT-4 powered SQL chatbot that translated natural language questions into executable queries over large MySQL schemas. While the model performed well in isolation, deploying it highlighted challenges around ambiguity, latency, and failure handling. I learned to design validation layers, fallback logic, and schema-aware prompts to ensure reliability under production workloads. Mapping workflows across dozens of interconnected tables deepened my appreciation for structured reasoning and defensive system design.

This role taught me that successful AI systems must anticipate misuse, uncertainty, and imperfect inputs rather than assuming ideal behavior.

---

## Corezi

My internship at Corezi introduced me to early-stage system integration, where AI components must coexist with existing software constraints. Working on applied data analysis and machine learning workflows, I gained firsthand exposure to the trade-offs between rapid experimentation and long-term maintainability.

Rather than optimizing isolated models, I focused on building clean, modular pipelines that could be iterated upon without destabilizing downstream systems. This experience reinforced the importance of disciplined data handling, incremental testing, and communication between technical components, lessons that continue to inform how I approach larger AI systems today.

---

## Reflection

Across these internships, I learned that building meaningful AI systems is a process of continual refinement rather than one-time optimization. Each experience strengthened my belief that intelligence emerges not just from models, but from how systems adapt, fail safely, and integrate into human workflows. These lessons continue to shape how I approach research, engineering, and the responsible deployment of AI in real-world environments.
